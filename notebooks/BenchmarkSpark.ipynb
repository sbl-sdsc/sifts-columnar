{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark using Spark Dataframe\n",
    "This benchmark demostrates the efficiency of using columnar data formats. Here we run 4 benchmarks on the complete PDB to Uniprot residue-level mapping with a total of 105,594,955 records as of July 28, 2018.\n",
    "\n",
    "1. Count number of records\n",
    "2. Run a query\n",
    "3. Join datasets\n",
    "4. Convert to a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of cores and thread per core\n",
    "cores = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 176 ms, sys: 65.8 ms, total: 242 ms\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[\" + str(cores) + \"]\").appName(\"Example\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.orc.impl\", \"native\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Count number of records\n",
    "Read PDB to UniProt mapping file in the ORC columnar data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records: 96162206\n",
      "CPU times: user 4.76 ms, sys: 2.59 ms, total: 7.35 ms\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Dataset in ORC format\n",
    "ds = spark.read.orc(\"../data/pdb2uniprot_residues.orc.lzo\").dropna()\n",
    "\n",
    "# Dataset in Parquet format\n",
    "#ds = spark.read.parquet(\"./data/pdb2uniprot_residues.parquet.gzip\").dropna()\n",
    "\n",
    "print(\"total number of records:\", ds.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Run a query\n",
    "## Find Mitogen-activated protein kinase 14\n",
    "Here we run a query for PDB - UniProt mappings for UniProt ID Q16539 (MK14_HUMAN) and retrieve their residue-level mappings for residues that are observed in the PDB structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct chains : 243\n",
      "Number of residue mappings: 82277\n",
      "+----------------+---------+---------+---------+----------+\n",
      "|structureChainId|pdbResNum|pdbSeqNum|uniprotId|uniprotNum|\n",
      "+----------------+---------+---------+---------+----------+\n",
      "|          2ZB1.A|        4|        4|   Q16539|         4|\n",
      "|          2ZB1.A|        5|        5|   Q16539|         5|\n",
      "|          2ZB1.A|        6|        6|   Q16539|         6|\n",
      "|          2ZB1.A|        7|        7|   Q16539|         7|\n",
      "|          2ZB1.A|        8|        8|   Q16539|         8|\n",
      "+----------------+---------+---------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 6.79 ms, sys: 3.24 ms, total: 10 ms\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mk14_human = ds.filter(\"uniprotId == 'Q16539'\").cache()\n",
    "\n",
    "print(\"Number of distinct chains :\", mk14_human.select(\"structureChainId\").distinct().count())\n",
    "print(\"Number of residue mappings:\", mk14_human.count())\n",
    "mk14_human.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Join operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 9330\n",
      "+------+\n",
      "|    id|\n",
      "+------+\n",
      "|4AAQ.L|\n",
      "|2WGG.A|\n",
      "|2GBF.A|\n",
      "|3IE2.D|\n",
      "|4XET.A|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a random dataset of ~10,000 chains\n",
    "sample = ds.sample(withReplacement=False, fraction=0.0001, seed=1).select(\"structureChainId\").withColumnRenamed(\"structureChainId\", \"id\").distinct().cache()\n",
    "\n",
    "print(\"Sample size:\", sample.count())\n",
    "sample.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use this sample dataset to run a database inner join for ~10,000 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of residue in subset: 3566391\n",
      "+----------------+---------+---------+---------+----------+\n",
      "|structureChainId|pdbResNum|pdbSeqNum|uniprotId|uniprotNum|\n",
      "+----------------+---------+---------+---------+----------+\n",
      "|          1CJ0.B|       -8|        1|   P07511|        15|\n",
      "|          1CJ0.B|       -7|        2|   P07511|        16|\n",
      "|          1CJ0.B|       -6|        3|   P07511|        17|\n",
      "|          1CJ0.B|       -5|        4|   P07511|        18|\n",
      "|          1CJ0.B|       -4|        5|   P07511|        19|\n",
      "+----------------+---------+---------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 6.22 ms, sys: 2.65 ms, total: 8.88 ms\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subset = ds.join(sample, ds.structureChainId == sample.id).drop(sample.id)\n",
    "\n",
    "print(\"Number of residue in subset:\", subset.count())\n",
    "subset.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Convert from Spark to Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 694 ms, sys: 115 ms, total: 809 ms\n",
      "Wall time: 1.52 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structureChainId</th>\n",
       "      <th>pdbResNum</th>\n",
       "      <th>pdbSeqNum</th>\n",
       "      <th>uniprotId</th>\n",
       "      <th>uniprotNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2ZB1.A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Q16539</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2ZB1.A</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Q16539</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2ZB1.A</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Q16539</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2ZB1.A</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Q16539</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2ZB1.A</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Q16539</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  structureChainId pdbResNum  pdbSeqNum uniprotId  uniprotNum\n",
       "0           2ZB1.A         4          4    Q16539           4\n",
       "1           2ZB1.A         5          5    Q16539           5\n",
       "2           2ZB1.A         6          6    Q16539           6\n",
       "3           2ZB1.A         7          7    Q16539           7\n",
       "4           2ZB1.A         8          8    Q16539           8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mk14_human.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark dataframe total time 66.6036639213562 sec.\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(\"Spark dataframe total time\", end-start, \"sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-13T20:20:21-08:00\n",
      "\n",
      "CPython 3.7.3\n",
      "IPython 7.10.1\n",
      "\n",
      "compiler   : Clang 9.0.0 (tags/RELEASE_900/final)\n",
      "system     : Darwin\n",
      "release    : 18.7.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
